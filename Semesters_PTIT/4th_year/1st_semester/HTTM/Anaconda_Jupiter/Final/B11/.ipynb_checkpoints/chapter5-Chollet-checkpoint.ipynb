{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9fba72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55744 (217.75 KB)\n",
      "Trainable params: 55744 (217.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Instantiating a small convnet\n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # Import các lớp (layers) và mô hình (models) từ thư viện Keras\n",
    "# from keras import layers\n",
    "# from keras import models\n",
    "\n",
    "# # Tạo một mô hình Sequential\n",
    "# model = models.Sequential()\n",
    "\n",
    "# # Thêm một lớp Convolutional 2D với 32 bộ lọc kích thước (3, 3), hàm kích hoạt 'relu' và kích thước đầu vào là (28, 28, 1)\n",
    "# model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# # Thêm một lớp MaxPooling 2D với kích thước cửa sổ (2, 2) để giảm kích thước của đầu ra\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Thêm một lớp Convolutional 2D khác với 64 bộ lọc kích thước (3, 3) và hàm kích hoạt 'relu'\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# # Thêm một lớp MaxPooling 2D với kích thước cửa sổ (2, 2) để giảm kích thước của đầu ra\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# # Thêm một lớp Convolutional 2D khác với 64 bộ lọc kích thước (3, 3) và hàm kích hoạt 'relu'\n",
    "# model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# # Hiển thị tóm tắt thông tin của mô hình\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb61ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Listing 5.2 Adding a classifier on top of the convnet\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# # Thêm một layer Flatten để chuyển đổi feature maps thành một vector 1D\n",
    "# model.add(layers.Flatten())\n",
    "\n",
    "# # Thêm một layer Dense với 64 đơn vị nơ-ron, hàm kích hoạt là 'relu'\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "\n",
    "# # Thêm một layer Dense khác với 10 đơn vị nơ-ron (số lượng lớp đầu ra), hàm kích hoạt là 'softmax'\n",
    "# model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# # In ra tổng quan về mô hình sau khi thêm các layer mới\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d9922b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 23s 24ms/step - loss: 0.1743 - accuracy: 0.9460\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 0.0479 - accuracy: 0.9851\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 23s 25ms/step - loss: 0.0317 - accuracy: 0.9897\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 25s 27ms/step - loss: 0.0252 - accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 24s 25ms/step - loss: 0.0197 - accuracy: 0.9939\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.0277 - accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9925000071525574"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing 5.3 Training the convnet on MNIST images\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "\n",
    "test_acc\n",
    "\n",
    "# # Import các modules và functions cần thiết từ thư viện Keras\n",
    "# from keras.datasets import mnist\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # Tải dữ liệu MNIST từ Keras\n",
    "# (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# # Reshape dữ liệu để phù hợp với input_shape của mô hình (28, 28, 1)\n",
    "# train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "# train_images = train_images.astype('float32') / 255\n",
    "\n",
    "# test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "# test_images = test_images.astype('float32') / 255\n",
    "\n",
    "# # Chuyển đổi nhãn (labels) thành dạng one-hot encoding\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)\n",
    "\n",
    "# # Compile mô hình với các thông số quan trọng như optimizer, loss function và metrics\n",
    "# model.compile(optimizer='rmsprop',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Huấn luyện mô hình trên dữ liệu huấn luyện\n",
    "# model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0d1b80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 64)        36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55744 (217.75 KB)\n",
      "Trainable params: 55744 (217.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_no_max_pool = models.Sequential()\n",
    "\n",
    "model_no_max_pool.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(28, 28, 1)))\n",
    "\n",
    "model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model_no_max_pool.summary()\n",
    "    \n",
    "# # Tạo một mô hình tuần tự mới không sử dụng layer MaxPooling\n",
    "# model_no_max_pool = models.Sequential()\n",
    "\n",
    "# # Thêm một layer Convolutional 2D với 32 bộ lọc, kích thước kernel là (3, 3), hàm kích hoạt là 'relu',\n",
    "# # và input_shape là (28, 28, 1) - đây là kích thước của ảnh đầu vào\n",
    "# model_no_max_pool.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# # Thêm một layer Convolutional 2D khác với 64 bộ lọc, kích thước kernel là (3, 3), hàm kích hoạt là 'relu'\n",
    "# model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# # Thêm một layer Convolutional 2D khác với 64 bộ lọc, kích thước kernel là (3, 3), hàm kích hoạt là 'relu'\n",
    "# model_no_max_pool.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# # In ra tổng quan về mô hình không sử dụng layer MaxPooling\n",
    "# model_no_max_pool.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78269d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'cats_and_dogs_small\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(base_dir)\n\u001b[0;32m      9\u001b[0m train_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(train_dir)\n\u001b[0;32m     11\u001b[0m validation_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(validation_dir)\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'cats_and_dogs_small\\\\train'"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = 'kaggle_original_data'\n",
    "\n",
    "base_dir = 'cats_and_dogs_small'\n",
    "if not os.path.exists(base_dir):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.exists(train_dir):\n",
    "    os.mkdir(train_dir)\n",
    "    \n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.mkdir(validation_dir)\n",
    "    \n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "os.mkdir(validation_dogs_dir)\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "os.mkdir(test_dogs_dir)\n",
    "\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "    \n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "                    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "                    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "                    \n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    if os.path.exists(src):\n",
    "        shutil.copy(src, dst)\n",
    "                                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
    "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
    "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
    "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
    "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
    "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbda3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.5 Instantiating a small convnet for dogs vs. cats classification\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b755af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.6 Configuring the model for training\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786caebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing 5.7 Using ImageDataGenerator to read images from directories\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d15371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.8 Fitting the model using a batch generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba510c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.9 Saving the model\n",
    "model.save('cats_and_dogs_small_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37022be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.10 Displaying curves of loss and accuracy during training\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39f1075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.11 Setting up a data augmentation configuration via ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492fac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.12 Displaying some randomly augmented training images\n",
    "from keras.preprocessing import image \n",
    "\n",
    "fnames = [os.path.join(train_cats_dir, fname) for\n",
    "    fname in os.listdir(train_cats_dir)]\n",
    "\n",
    "img_path = fnames[3]\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i=0\n",
    "\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(image.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d392b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.13 Defining a new convnet that includes dropout\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer=optimizers.RMSprop(learning_rate=1e-4),\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982ce4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.14 Training the convnet using data-augmentation generators\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "total_train_samples = len(train_generator.filenames)\n",
    "total_validation_samples = len(validation_generator.filenames)\n",
    "\n",
    "steps_per_epoch = np.ceil(total_train_samples / train_generator.batch_size)\n",
    "validation_steps = np.ceil(total_validation_samples / validation_generator.batch_size)\n",
    "\n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=30,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.15 Saving the model\n",
    "model.save('cats_and_dogs_small_2.h5')\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.16 Instantiating the VGG16 convolutional base\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                include_top=False,\n",
    "                input_shape=(150, 150, 3))\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d197d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.17 Extracting features using the pretrained convolutional base\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "base_dir = 'cats_and_dogs_small'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 2000)\n",
    "validation_features, validation_labels = extract_features(validation_dir, 1000)\n",
    "test_features, test_labels = extract_features(test_dir, 1000)\n",
    "\n",
    "train_features = np.reshape(train_features, (2000, 4*4* 512))\n",
    "validation_features = np.reshape(validation_features, (1000, 4*4* 512))\n",
    "test_features = np.reshape(test_features, (1000, 4*4* 512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.18 Defining and training the densely connected classifier\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=4 * 4 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=30,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9085bad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.19 Plotting the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4aa59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.20 Adding a densely connected classifier on top of the convolutional base\n",
    "from keras import models\n",
    "from keras import layers\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3db9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.21 Training the model end to end with a frozen convolutional base\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer=optimizers.RMSprop(learning_rate=2e-5),\n",
    "        metrics=['acc'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "# Lấy thông tin lịch sử từ quá trình huấn luyện\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "# Hiển thị đồ thị\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2035a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.22 Freezing all layers up to a specific one\n",
    "conv_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ced0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.23 Fine-tuning the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "        optimizer=optimizers.RMSprop(lr=1e-5),\n",
    "        metrics=['acc'])\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c685ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.24 Smoothing the plots\n",
    "def smooth_curve(points, factor=0.8):\n",
    "    smoothed_points = []\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(acc), 'bo', label='Smoothed training acc')\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_acc), 'b', label='Smoothed validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(loss), 'bo', label='Smoothed training loss')\n",
    "plt.plot(epochs,\n",
    "        smooth_curve(val_loss), 'b', label='Smoothed validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1be3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cats_and_dogs_small_2.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8832189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.25 Preprocessing a single image\n",
    "img_path = 'C:/Users/HP/Desktop/Demo/cats_and_dogs_small/test/cats/cat.1700.jpg'\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img(img_path, target_size=(150, 150))\n",
    "img_tensor = image.img_to_array(img)\n",
    "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "img_tensor /= 255.\n",
    "\n",
    "print(img_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e40299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.26 Display the test picture \n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img_tensor[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.27 Instantiating a model from an input tensor and a list of output tensors\n",
    "from keras import models\n",
    "\n",
    "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
    "activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5bb7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.28 Running the model in predict mode\n",
    "activations = activation_model.predict(img_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea268ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_activation = activations[0]\n",
    "print(first_layer_activation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0a9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.29 Visualizing the fourth channel\n",
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(first_layer_activation[0, :, :, 4], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f414e0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.30 Visualizing the seventh channel\n",
    "plt.matshow(first_layer_activation[0, :, :, 7], cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f0e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.31 Visualizing every channel in every intermediate activation\n",
    "layer_names = []\n",
    "for layer in model.layers[:8]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "images_per_row = 16\n",
    "\n",
    "for layer_name, layer_activation in zip(layer_names, activations):\n",
    "    n_features = layer_activation.shape[-1]\n",
    "    size = layer_activation.shape[1]\n",
    "    n_cols = n_features // images_per_row\n",
    "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
    "\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_image = layer_activation[0, :, :, col * images_per_row + row]\n",
    "\n",
    "            # Xử lý giá trị không hợp lệ hoặc vô hạn\n",
    "            if np.isnan(channel_image).any() or np.isinf(channel_image).any():\n",
    "                # Xử lý giá trị không hợp lệ, ví dụ: đặt chúng thành giá trị mặc định hoặc loại bỏ kênh\n",
    "                channel_image = np.zeros_like(channel_image)  # Đặt tất cả giá trị thành 0\n",
    "\n",
    "            channel_image -= channel_image.mean()\n",
    "            channel_image /= (channel_image.std() + 1e-8)  # Thêm một số rất nhỏ để tránh chia cho 0\n",
    "            channel_image *= 64\n",
    "            channel_image += 128\n",
    "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "            \n",
    "            display_grid[col * size: (col + 1) * size,\n",
    "                         row * size: (row + 1) * size] = channel_image\n",
    "\n",
    "    scale = 1. / size\n",
    "    plt.figure(figsize=(scale * display_grid.shape[1], scale * display_grid.shape[0]))\n",
    "    plt.title(layer_name)\n",
    "    plt.grid(False)\n",
    "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3045930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.32 Defining the loss tensor for filter visualization\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "model = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "layer_name = 'block3_conv1'\n",
    "filter_index = 0\n",
    "\n",
    "layer_output = model.get_layer(layer_name).output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# 5.33 Obtain the output tensor of the selected layer\n",
    "grads = K.gradients(loss, model.input)[0]\n",
    "\n",
    "# 5.34 Gradient-normalization trick\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# 5.35 Fetching Numpy output values given Numpy input values\n",
    "iterate = K.function([model.input], [loss, grads])\n",
    "\n",
    "import numpy as np\n",
    "loss_value, grads_value = iterate([np.zeros((1, 150, 150, 3))])\n",
    "\n",
    "# 5.36 Loss maximization via stochastic gradient descent\n",
    "input_img_data = np.random.random((1, 150, 150, 3)) * 20 + 128.\n",
    "\n",
    "step = 1.\n",
    "for i in range(40):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    \n",
    "    input_img_data += grads_value * step\n",
    "\n",
    "# 5.37 Utility function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "    x *= 255\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# 5.38 Function to generate a filter visualization pattern\n",
    "def generate_pattern(layer_name, filter_index, size=150):\n",
    "    layer_output = model.get_layer(layer_name).output\n",
    "    loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "    grads = K.gradients(loss, model.input)[0]\n",
    "    grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "    iterate = K.function([model.input], [loss, grads])\n",
    "    input_img_data = np.random.random((1, size, size, 3)) * 20 + 128.\n",
    "    step = 1.\n",
    "    for i in range(40):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "    img = input_img_data[0]\n",
    "    return deprocess_image(img)\n",
    "\n",
    "# Display a single filter response pattern\n",
    "plt.imshow(generate_pattern('block3_conv1', 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d505be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.39 Generate a grid of all filter response patterns in a layer\n",
    "layer_name = 'block1_conv1'\n",
    "size = 64\n",
    "margin = 5\n",
    "\n",
    "results = np.zeros((8 * size+7* margin, 8 * size+7* margin, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        filter_img = generate_pattern(layer_name, i + (j * 8), size=size)\n",
    "        \n",
    "        horizontal_start = i * size + i * margin\n",
    "        horizontal_end = horizontal_start + size\n",
    "        vertical_start = j * size + j * margin\n",
    "        vertical_end = vertical_start + size\n",
    "        results[horizontal_start: horizontal_end,\n",
    "                vertical_start: vertical_end, :] = filter_img\n",
    "        \n",
    "results = np.clip(results, 0, 255).astype('uint8')\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c072d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.40 Loading the VGG16 network with pretrained weights\n",
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16(weights='imagenet')\n",
    "\n",
    "# 5.41 Preprocessing an input image for VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'C:/Users/HP/Desktop/Demo/cats_and_dogs_small/test/cats/cat.1700.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539e193",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(x)\n",
    "decoded_preds = decode_predictions(preds, top=3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57820d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.42 Setting up the Grad-CAM algorithm\n",
    "african_elephant_output = model.output[:, 386]\n",
    "last_conv_layer = model.get_layer('block5_conv3')\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0]\n",
    "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x])\n",
    "\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "\n",
    "heatmap = np.mean(conv_layer_output_value, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71749cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.43 Heatmap post-processing\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac64303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.44 Superimposing the heatmap with the original picture\n",
    "import cv2\n",
    "img = cv2.imread(img_path)\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "cv2.imwrite('cats_and_dogs_small/test/cats/cat.1700.jpg', superimposed_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
