{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f54792-2edd-40fc-846c-6f3f6858c113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Đường dẫn đến thư mục chứa các tệp ảnh\n",
    "# folder_path = \"Original/TuongTu\"\n",
    "\n",
    "# # Lấy danh sách các tệp trong thư mục\n",
    "# file_list = os.listdir(folder_path)\n",
    "\n",
    "# # Lặp qua từng tệp và đổi tên\n",
    "# for index, filename in enumerate(file_list):\n",
    "#     # Tạo tên mới với \"that_tinh_\" + chỉ mục\n",
    "#     new_filename = f\"tuong_tu_{index}{os.path.splitext(filename)[-1]}\"\n",
    "    \n",
    "#     # new_filename = f\"hello_{index}{os.path.splitext(filename)[-1]}\"\n",
    "\n",
    "#     # Đường dẫn tệp cũ và mới\n",
    "#     old_filepath = os.path.join(folder_path, filename)\n",
    "#     new_filepath = os.path.join(folder_path, new_filename)\n",
    "\n",
    "#     # Đổi tên tệp\n",
    "#     os.rename(old_filepath, new_filepath)\n",
    "\n",
    "# print(\"Đã đổi tên các tệp ảnh thành công!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89ea4f-9dc3-4edf-b1dd-2e7cff144ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo thành công!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "# -------------------------------Tạo các tệp cân thiết ---------------------------------------------------------\n",
    "def check_folder_exist(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "\n",
    "# Đường dẫn đến thư mục nơi bộ dữ liệu gốc đã được giải nén\n",
    "original_dataset_dir = Path('Original')\n",
    "# Đường dẫn đến thư mục nơi bộ dữ liệu đã qua xử lý\n",
    "processed_dataset_dir = Path('Processed')\n",
    "check_folder_exist(processed_dataset_dir)\n",
    "# Đường dẫn đến thư mục nơi bộ dữ liệu dùng để huấn luyện, xác thực và kiểm tra\n",
    "base_dir = Path('Base')\n",
    "check_folder_exist(base_dir)\n",
    "\n",
    "processed_loving_dir = os.path.join(processed_dataset_dir, 'DangYeu')\n",
    "check_folder_exist(processed_loving_dir)\n",
    "processed_lovelorn_dir = os.path.join(processed_dataset_dir, 'ThatTinh')\n",
    "check_folder_exist(processed_lovelorn_dir)\n",
    "processed_lovesick_dir = os.path.join(processed_dataset_dir, 'TuongTu')\n",
    "check_folder_exist(processed_lovesick_dir)\n",
    "\n",
    "# Các thư mục cho các phần tách huấn luyện, xác thực và kiểm thử\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "check_folder_exist(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "check_folder_exist(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "check_folder_exist(test_dir)\n",
    "\n",
    "# Thư mục với hình ảnh đang yêu huấn luyện\n",
    "train_loving_dir = os.path.join(train_dir, 'DangYeu')\n",
    "check_folder_exist(train_loving_dir)\n",
    "\n",
    "# Thư mục với hình ảnh thất tình huấn luyện\n",
    "train_lovelorn_dir = os.path.join(train_dir, 'ThatTinh')\n",
    "check_folder_exist(train_lovelorn_dir)\n",
    "\n",
    "# Thư mục với hình ảnh tương tư huấn luyện\n",
    "train_lovesick_dir = os.path.join(train_dir, 'TuongTu')\n",
    "check_folder_exist(train_lovesick_dir)\n",
    "\n",
    "# Thư mục với hình ảnh đang yêu xác thực\n",
    "validation_loving_dir = os.path.join(validation_dir, 'DangYeu')\n",
    "check_folder_exist(validation_loving_dir)\n",
    "\n",
    "# Thư mục với hình ảnh thất tình xác thực\n",
    "validation_lovelorn_dir = os.path.join(validation_dir, 'ThatTinh')\n",
    "check_folder_exist(validation_lovelorn_dir)\n",
    "\n",
    "# Thư mục với hình ảnh tương tư xác thực\n",
    "validation_lovesick_dir = os.path.join(validation_dir, 'TuongTu')\n",
    "check_folder_exist(validation_lovesick_dir)\n",
    "\n",
    "# Thư mục với hình ảnh đang yêu kiểm thử\n",
    "test_loving_dir = os.path.join(test_dir, 'DangYeu')\n",
    "check_folder_exist(test_loving_dir)\n",
    "\n",
    "# Thư mục với hình ảnh thất tình kiểm thử\n",
    "test_lovelorn_dir = os.path.join(test_dir, 'ThatTinh')\n",
    "check_folder_exist(test_lovelorn_dir)\n",
    "\n",
    "# Thư mục với hình ảnh tương tư kiểm thử\n",
    "test_lovesick_dir = os.path.join(test_dir, 'TuongTu')\n",
    "check_folder_exist(test_lovesick_dir)\n",
    "print(\"Tạo thành công!\")\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def convert_images_to_jpg(input_folder, output_folder):\n",
    "    # Lặp qua tất cả tệp trong thư mục đầu vào\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Kiểm tra nếu tệp là hình ảnh\n",
    "        if os.path.isfile(input_path) or any(input_path.lower().endswith(ext) for ext in ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp')):\n",
    "            # Đọc và chuyển đổi hình ảnh thành định dạng JPG\n",
    "            try:\n",
    "                image = Image.open(input_path)\n",
    "                if image.mode == 'RGBA' or image.mode == 'P':\n",
    "                    image = image.convert('RGB')\n",
    "                output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '.jpg')\n",
    "                image.save(output_path, 'JPEG')\n",
    "            except Exception as e:\n",
    "                os.remove(input_path)\n",
    "                print(f\"Lỗi khi chuyển đổi {input_path}: {str(e)}\")\n",
    "\n",
    "# Định nghĩa các thư mục nguồn cho mỗi loại hình ảnh\n",
    "source_loving_dir = os.path.join(original_dataset_dir, 'DangYeu')\n",
    "source_lovelorn_dir = os.path.join(original_dataset_dir, 'ThatTinh')\n",
    "source_lovesick_dir = os.path.join(original_dataset_dir, 'TuongTu')\n",
    "\n",
    "convert_images_to_jpg(source_loving_dir, processed_loving_dir)\n",
    "convert_images_to_jpg(source_lovelorn_dir, processed_lovelorn_dir)\n",
    "convert_images_to_jpg(source_lovesick_dir, processed_lovesick_dir)\n",
    "print(\"Convert done!\")\n",
    "\n",
    "# def reduce_image_size(image_path, output_path):\n",
    "#   image = PIL.Image.open(image_path)\n",
    "#   image.resize((640, 480), PIL.Image.ANTIALIAS)\n",
    "#   image.save(output_path, quality=80)\n",
    "\n",
    "# for image in os.listdir(source_loving_dir):\n",
    "#     print(os.path.join(source_loving_dir, image))\n",
    "#     reduce_image_size(os.path.join(source_loving_dir, image), os.path.join(source_loving_dir, image))\n",
    "    \n",
    "# for image in os.listdir(source_lovelorn_dir):\n",
    "#     reduce_image_size(os.path.join(source_lovelorn_dir, image), os.path.join(source_lovelorn_dir, image))\n",
    "    \n",
    "# for image in os.listdir(source_lovesick_dir):\n",
    "#     reduce_image_size(os.path.join(source_lovesick_dir, image), os.path.join(source_lovesick_dir, image))\n",
    "\n",
    "# print(\"Resize done!\")\n",
    "\n",
    "\n",
    "\n",
    "# Lấy danh sách các tệp hình ảnh trong từng thư mục đã qua xử lý\n",
    "loving_images = os.listdir(processed_loving_dir)\n",
    "lovelorn_images = os.listdir(processed_lovelorn_dir)\n",
    "lovesick_images = os.listdir(processed_lovesick_dir)\n",
    "\n",
    "# Tính số lượng hình ảnh cho từng tập dữ liệu\n",
    "loving_images_count = len(loving_images)\n",
    "lovelorn_images_count = len(lovelorn_images)\n",
    "lovesick_images_count = len(lovesick_images)\n",
    "\n",
    "train_loving_count = int(loving_images_count * 0.7)\n",
    "validation_loving_count = int(loving_images_count * 0.2)\n",
    "test_loving_count = loving_images_count - train_loving_count - validation_loving_count\n",
    "\n",
    "train_lovelorn_count = int(lovelorn_images_count * 0.7)\n",
    "validation_lovelorn_count = int(lovelorn_images_count * 0.2)\n",
    "test_lovelorn_count = lovelorn_images_count - train_lovelorn_count - validation_lovelorn_count\n",
    "\n",
    "train_lovesick_count = int(lovesick_images_count * 0.7)\n",
    "validation_lovesick_count = int(lovesick_images_count * 0.2)\n",
    "test_lovesick_count = lovesick_images_count - train_lovesick_count - validation_lovesick_count\n",
    "\n",
    "# Di chuyển hình ảnh vào các thư mục tương ứng\n",
    "for image in loving_images[:train_loving_count]:\n",
    "    source = os.path.join(processed_loving_dir, image)\n",
    "    destination = os.path.join(train_loving_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in loving_images[train_loving_count:train_loving_count + validation_loving_count]:\n",
    "    source = os.path.join(processed_loving_dir, image)\n",
    "    destination = os.path.join(validation_loving_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in loving_images[train_loving_count + validation_loving_count:train_loving_count + validation_loving_count + test_loving_count]:\n",
    "    source = os.path.join(processed_loving_dir, image)\n",
    "    destination = os.path.join(test_loving_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "    \n",
    "for image in lovelorn_images[:train_lovelorn_count]:\n",
    "    source = os.path.join(processed_lovelorn_dir, image)\n",
    "    destination = os.path.join(train_lovelorn_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in lovelorn_images[train_lovelorn_count:train_lovelorn_count + validation_lovelorn_count]:\n",
    "    source = os.path.join(processed_lovelorn_dir, image)\n",
    "    destination = os.path.join(validation_lovelorn_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in lovelorn_images[train_lovelorn_count + validation_lovelorn_count:train_lovelorn_count + validation_lovelorn_count + test_lovelorn_count]:\n",
    "    source = os.path.join(processed_lovelorn_dir, image)\n",
    "    destination = os.path.join(test_lovelorn_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "    \n",
    "for image in lovesick_images[:train_lovesick_count]:\n",
    "    source = os.path.join(processed_lovesick_dir, image)\n",
    "    destination = os.path.join(train_lovesick_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in lovesick_images[train_lovesick_count:train_lovesick_count + validation_lovesick_count]:\n",
    "    source = os.path.join(processed_lovesick_dir, image)\n",
    "    destination = os.path.join(validation_lovesick_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "for image in lovesick_images[train_lovesick_count + validation_lovesick_count:train_lovesick_count + validation_lovesick_count + test_lovesick_count]:\n",
    "    source = os.path.join(processed_lovesick_dir, image)\n",
    "    destination = os.path.join(test_lovesick_dir, image)\n",
    "    shutil.copy(source, destination)\n",
    "\n",
    "print(\"Chia tập dữ liệu thành công!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad0a833-de3a-4f56-9549-6df58824d3c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('total training loving images:', len(os.listdir(train_loving_dir)))\n",
    "print('total validation loving images:', len(os.listdir(validation_loving_dir)))\n",
    "print('total test loving images:', len(os.listdir(test_loving_dir)))\n",
    "\n",
    "print('total training lovelorn images:', len(os.listdir(train_lovelorn_dir)))\n",
    "print('total validation lovelorn images:', len(os.listdir(validation_lovelorn_dir)))\n",
    "print('total test lovelorn images:', len(os.listdir(test_lovelorn_dir)))\n",
    "\n",
    "print('total training lovesick images:', len(os.listdir(train_lovesick_dir)))\n",
    "print('total validation lovesick images:', len(os.listdir(validation_lovesick_dir)))\n",
    "print('total test lovesick images:', len(os.listdir(test_lovesick_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0147b-d7c0-41ee-a2de-09caa290cf38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dữ liệu training và validation\n",
    "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=4,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=42\n",
    ")\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=4,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Đánh giá mô hình trên tập dữ liệu test\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    base_dir,\n",
    "    image_size=(150, 150),\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "# Tạo mô hình\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "model_1.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "model_1.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_1.add(MaxPooling2D((2, 2)))\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dropout(0.2))\n",
    "model_1.add(Dense(512, activation='relu'))\n",
    "model_1.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile mô hình\n",
    "model_1.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Đào tạo mô hình\n",
    "history = model_1.fit(train_dataset, epochs=100, validation_data=validation_dataset)\n",
    "\n",
    "# Lấy thông tin accuracy và loss của tập kiểm tra\n",
    "test_loss, test_accuracy = model_1.evaluate(test_dataset)\n",
    "\n",
    "# Tạo biểu đồ so sánh\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Biểu đồ Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Biểu đồ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1d7a7-e743-47dc-a327-9a87dbb2c047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Đường dẫn đến thư mục chứa ảnh cần dự đoán\n",
    "img_path = 'C:/Users/PhucQuach/OneDrive/Desktop/TKHTTM/BaiTap8/DangYeu'\n",
    "\n",
    "# Lặp qua tất cả các tệp hình ảnh trong thư mục\n",
    "for filename in os.listdir(img_path):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Đường dẫn đầy đủ đến tệp ảnh\n",
    "        img_full_path = os.path.join(img_path, filename)\n",
    "\n",
    "        # Đọc ảnh và điều chỉnh kích thước\n",
    "        img = image.load_img(img_full_path, target_size=(150, 150))\n",
    "\n",
    "        # Chuyển ảnh thành mảng numpy và mở rộng để phù hợp với kích thước đầu vào của mô hình\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Chuẩn hóa ảnh tương tự như trong quá trình đào tạo (nếu cần)\n",
    "        # img_array /= 255.0  # Chuẩn hóa các giá trị pixel trong khoảng [0, 1]\n",
    "\n",
    "        # Dự đoán nhãn\n",
    "        predictions = model_1.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "        # Dự đoán xem ảnh thuộc nhóm nào\n",
    "        class_names = ['DangYeu', 'ThatTinh', 'TuongTu']\n",
    "        predicted_label = class_names[predicted_class]\n",
    "\n",
    "        print(f'Predicted label for {filename}: {predicted_label}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc8411-0bf1-42d7-a4d7-71e242285587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mô hình 2\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dropout(0.2))\n",
    "model_2.add(Dense(512, activation='relu'))\n",
    "model_2.add(Dense(3, activation='softmax'))\n",
    "            \n",
    "# Compile mô hình\n",
    "model_2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Đào tạo mô hình\n",
    "history = model_2.fit(train_dataset, epochs=30, validation_data=validation_dataset)\n",
    "\n",
    "# Lấy thông tin accuracy và loss của tập kiểm tra\n",
    "test_loss, test_accuracy = model_2.evaluate(test_dataset)\n",
    "\n",
    "# Tạo biểu đồ so sánh\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Biểu đồ Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Biểu đồ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4534c731-8e5c-4889-b448-7ae3ed5bf873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Mô hình 3\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model_3.add(MaxPooling2D((2, 2)))\n",
    "model_3.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_3.add(MaxPooling2D((2, 2)))\n",
    "model_3.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_3.add(MaxPooling2D((2, 2)))\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dropout(0.2))\n",
    "model_3.add(Dense(512, activation='relu'))\n",
    "model_3.add(Dense(3, activation='softmax'))\n",
    "            \n",
    "# Compile mô hình\n",
    "model_3.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Đào tạo mô hình\n",
    "history = model_3.fit(train_dataset, epochs=30, validation_data=validation_dataset)\n",
    "\n",
    "# Lấy thông tin accuracy và loss của tập kiểm tra\n",
    "test_loss, test_accuracy = model_3.evaluate(test_dataset)\n",
    "\n",
    "# Tạo biểu đồ so sánh\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Biểu đồ Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axhline(y=test_accuracy, color='r', linestyle='--', label='Test Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Biểu đồ Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.axhline(y=test_loss, color='r', linestyle='--', label='Test Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
